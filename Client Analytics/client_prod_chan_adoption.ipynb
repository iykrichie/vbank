{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b145176-22f7-41ee-81ca-44151d7d44ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Product & Channel Adoption\n",
    "## Client Channel and Product Usage Analysis\n",
    "\n",
    "## Objective:\n",
    "The purpose of this script is to analyze the usage patterns of different channels and products among clients in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43e47ccb-ef3d-4625-82e9-969696675d77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c9f856-dff0-4387-b963-d2984b584b68",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Libraries Used:\n",
    "- `sqlalchemy`: Used to create an engine for connecting to databases.\n",
    "- `pandas`: Used for data manipulation and analysis.\n",
    "- `numpy`: Optional library often used in conjunction with Pandas for numerical computations.\n",
    "\n",
    "## Code Details:\n",
    "1. **Import Statements:**\n",
    "   - `from sqlalchemy import create_engine`: Imports the `create_engine` function from the `sqlalchemy` library, which is used to create a connection engine for the database.\n",
    "   - `import pandas as pd`: Imports the `pandas` library using the alias `pd`, which is a popular library for data manipulation and analysis in Python.\n",
    "   - `import numpy as np`: Imports the `numpy` library using the alias `np`, which is commonly used for numerical computations in Python, often alongside Pandas.\n",
    "\n",
    "2. **Code Usage:**\n",
    "   - `create_engine`: The `create_engine` function is used to create an engine object that connects to a database. This engine object can then be used by Pandas or SQLAlchemy to interact with the database.\n",
    "\n",
    "3. **Data Handling:**\n",
    "   This code snippet sets up the necessary libraries for data handling but does not perform any specific data operations. However, with the `create_engine` function from SQLAlchemy and the data manipulation capabilities of Pandas and NumPy, various data operations such as querying databases, data cleaning, analysis, and more can be performed efficiently.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41fcf431-280e-4193-8ddb-d7a884f2da12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/Workspace/Credentials/db_data.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "\n",
    "host = data['redshift']['host']\n",
    "user = data['redshift']['user']\n",
    "passwd = data['redshift']['passwd']\n",
    "database = data['redshift']['database']\n",
    "\n",
    "conn = create_engine(f\"postgresql+psycopg2://{user}:{passwd}@{host}:5439/{database}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "568a5d0e-d687-4b6e-a7e4-cf5cf2701210",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "yesterday =  (datetime.today() - timedelta(days = 1)).strftime('%Y-%m-%d')\n",
    "print(today)\n",
    "print(yesterday)\n",
    "\n",
    "\n",
    "last_2_wks = datetime.today() - timedelta(days = 14)\n",
    "last_2_wks = last_2_wks.strftime('%Y-%m-%d')\n",
    "print('------------------------------------')\n",
    "print(last_2_wks)\n",
    "\n",
    "print('\\n')\n",
    "now = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "last_30_mins = (datetime.today() - timedelta(days = 1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "trunc_last_30_mins = (datetime.today() - timedelta(days = 1)).strftime('%Y-%m-%d %H:%M')\n",
    "print(last_30_mins, 'to', now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6a69344-6908-40a7-8b71-898a3b99fcbe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Objective:\n",
    "The purpose of this code snippet is to load database connection credentials from a JSON file and use them to create a connection engine for PostgreSQL using SQLAlchemy.\n",
    "\n",
    "## Code Details:\n",
    "1. **Import Statement:**\n",
    "   - `import json`: Imports the `json` module, which provides functions for working with JSON data in Python.\n",
    "\n",
    "2. **Loading JSON Data:**\n",
    "   ```python\n",
    "   with open('/Workspace/Credentials/db_data.json', 'r') as fp:\n",
    "       data = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7fc1f40-7303-43e8-b0e8-a92bcb1a2dca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Query Details:\n",
    "The script starts by defining several Common Table Expressions (CTEs) to categorize clients based on their transaction channels and account products:\n",
    "- `mobile_clients`: Clients using the 'MOBILE' channel.\n",
    "- `ussd_clients`: Clients using the 'USSD' channel.\n",
    "- `chatbot_clients`: Clients using the 'CHATBOT' channel.\n",
    "- `wallet_clients`: Clients using the 'WALLET' channel.\n",
    "- `bills_clients`: Clients with bill payments.\n",
    "- `airtime_clients`: Clients buying airtime or data.\n",
    "- `cardless_clients`: Clients performing cardless transactions.\n",
    "- `interbank_clients`: Clients with interbank outflows.\n",
    "- `card_clients`: Clients with card transactions.\n",
    "- `USA_clients`: Clients with a 'Universal Savings Account'.\n",
    "- `fd_clients`: Clients with a 'Term Fixed Deposit'.\n",
    "- `target_savings_clients`: Clients with a 'Target Savings Account'.\n",
    "- `child_savings_clients`: Clients with a 'Child Savings' account.\n",
    "- `corp_current_clients`: Clients with a 'Corporate Current Account'.\n",
    "- `ind_current_clients`: Clients with an 'Individual Current Account'.\n",
    "- `staff_current_clients`: Clients with a 'Staff Current Account'.\n",
    "- `credit_clients`: Active clients with loans.\n",
    "\n",
    "The main query then joins these CTEs with the `dwh_all_clients` table and other relevant tables to generate a report with the following columns:\n",
    "- `client_id`: Unique identifier for the client.\n",
    "- `client_category`: Category of the client.\n",
    "- `uses_mobile`: Flag indicating if the client uses the 'MOBILE' channel.\n",
    "- `uses_ussd`: Flag indicating if the client uses the 'USSD' channel.\n",
    "- `uses_chatbot`: Flag indicating if the client uses the 'CHATBOT' channel.\n",
    "- `uses_wallet`: Flag indicating if the client uses the 'WALLET' channel.\n",
    "- `pays_bills`: Flag indicating if the client pays bills.\n",
    "- `buys_airtime_data`: Flag indicating if the client buys airtime or data.\n",
    "- `does_cardless`: Flag indicating if the client performs cardless transactions.\n",
    "- `does_interbank_outflow`: Flag indicating if the client has interbank outflows.\n",
    "- `has_card`: Flag indicating if the client has a card.\n",
    "- `has_usa`: Flag indicating if the client has a 'Universal Savings Account'.\n",
    "- `has_fd`: Flag indicating if the client has a 'Term Fixed Deposit'.\n",
    "- `has_target_savings`: Flag indicating if the client has a 'Target Savings Account'.\n",
    "- `has_child_savings`: Flag indicating if the client has a 'Child Savings' account.\n",
    "- `has_corp_current`: Flag indicating if the client has a 'Corporate Current Account'.\n",
    "- `has_indv_current`: Flag indicating if the client has an 'Individual Current Account'.\n",
    "- `has_staff_current`: Flag indicating if the client has a 'Staff Current Account'.\n",
    "- `has_credit`: Flag indicating if the client has an active credit (loan) account.\n",
    "- `run_date`: Date when the script was executed.\n",
    "\n",
    "The resulting dataset `rcadop` provides insights into the usage patterns of different channels and products among clients at the time of execution.\n",
    "\n",
    "## Execution Time:\n",
    "The `%%time` magic command at the beginning measures the execution time of this script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab8e91d1-c96e-4284-b272-18c26290e861",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "query_data = pd.read_sql_query(f'''\n",
    "\n",
    "\n",
    "        WITH mobile_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_all_transactions\n",
    "            WHERE channel = 'MOBILE'\n",
    "        ),\n",
    "        ussd_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_all_transactions\n",
    "            WHERE channel = 'USSD'\n",
    "        ),\n",
    "        chatbot_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_all_transactions\n",
    "            WHERE channel = 'CHATBOT'\n",
    "        ),\n",
    "        wallet_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_all_transactions\n",
    "            WHERE channel = 'WALLET'\n",
    "        ),\n",
    "        bills_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_bills_only\n",
    "        ),\n",
    "        airtime_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_airtime_only\n",
    "        ),\n",
    "        cardless_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_cardless_transactions\n",
    "        ),\n",
    "        interbank_clients AS (\n",
    "            SELECT DISTINCT client_id\n",
    "            FROM dwh_interbank_outflows\n",
    "        ),\n",
    "        card_clients AS (\n",
    "            select distinct client_id from\n",
    "            dwh_card_transactions\n",
    "        ),\n",
    "        USA_clients as (\n",
    "            select distinct client_id\n",
    "            from dwh_all_accounts \n",
    "            where product_name = 'Universal Savings Account'\n",
    "        ),\n",
    "        fd_clients as (\n",
    "            select distinct client_id\n",
    "            from dwh_all_accounts daa  \n",
    "            where product_name = 'Term Fixed Deposit'\n",
    "        ),\n",
    "        target_savings_clients as (\n",
    "            select distinct client_id\n",
    "            from dwh_all_accounts \n",
    "            where product_name = 'Target Savings Account'\n",
    "        ),\n",
    "        child_savings_clients as (\n",
    "            select distinct client_id\n",
    "            from dwh_all_accounts\n",
    "            where product_name = 'Child Savings'\n",
    "        ),\n",
    "        corp_current_clients as (\n",
    "            select distinct client_id\n",
    "            from dwh_all_accounts daa  \n",
    "            where product_name = 'Corporate Current Account'\n",
    "        ),\n",
    "        ind_current_clients as (\n",
    "            select distinct client_id\n",
    "            from dwh_all_accounts \n",
    "            where product_name = 'Individual Current Account'\n",
    "        ),\n",
    "        staff_current_clients as (\n",
    "            select distinct client_id\n",
    "            from dwh_all_accounts\n",
    "            where product_name = 'Staff Current Account'\n",
    "        ),\n",
    "        credit_clients as (\n",
    "            select distinct client_id from dwh_loan_details \n",
    "            where loan_status = 'Active'\n",
    "        )\n",
    "\n",
    "            \n",
    "\n",
    "        SELECT\n",
    "            distinct \n",
    "            dac.client_id,  dac.client_category,\n",
    "            CASE WHEN mc.client_id IS NOT NULL THEN '1' ELSE '0' END AS uses_mobile,\n",
    "            CASE WHEN uc.client_id IS NOT NULL THEN '1' ELSE '0' END AS uses_ussd,\n",
    "            CASE WHEN cc.client_id IS NOT NULL THEN '1' ELSE '0' END AS uses_chatbot,\n",
    "            CASE WHEN wc.client_id IS NOT NULL THEN '1' ELSE '0' END AS uses_wallet,\n",
    "            CASE WHEN bc.client_id IS NOT NULL THEN '1' ELSE '0' END AS pays_bills,\n",
    "            CASE WHEN ac.client_id IS NOT NULL THEN '1' ELSE '0' END AS buys_airtime_data,\n",
    "            CASE WHEN ccless.client_id IS NOT NULL THEN '1' ELSE '0' END AS does_cardless,\n",
    "            CASE WHEN ic.client_id IS NOT NULL THEN '1' ELSE '0' END AS does_interbank_outflow,\n",
    "            CASE WHEN dc.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_card,\n",
    "            CASE WHEN uc1.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_usa,\n",
    "            CASE WHEN fd.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_fd,\n",
    "            CASE WHEN tsc.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_target_savings,\n",
    "            CASE WHEN csc.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_child_savings,\n",
    "            CASE WHEN ccc.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_corp_current,\n",
    "            CASE WHEN icc.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_indv_current,\n",
    "            CASE WHEN scc.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_staff_current,\n",
    "            CASE WHEN cc1.client_id IS NOT NULL THEN '1' ELSE '0' END AS has_credit,\n",
    "\n",
    "            current_date as run_date\n",
    "            \n",
    "        FROM dwh_all_clients dac\n",
    "        left join dwh_all_accounts daa on dac.client_id = daa.client_id \n",
    "        LEFT JOIN mobile_clients mc ON dac.client_id = mc.client_id\n",
    "        LEFT JOIN ussd_clients uc ON dac.client_id = uc.client_id\n",
    "        LEFT JOIN chatbot_clients cc ON dac.client_id = cc.client_id\n",
    "        LEFT JOIN wallet_clients wc ON dac.client_id = wc.client_id\n",
    "        LEFT JOIN bills_clients bc ON dac.client_id = bc.client_id\n",
    "        LEFT JOIN airtime_clients ac ON dac.client_id = ac.client_id\n",
    "        LEFT JOIN cardless_clients ccless ON dac.client_id = ccless.client_id\n",
    "        LEFT JOIN interbank_clients ic ON dac.client_id = ic.client_id\n",
    "        LEFT JOIN card_clients dc ON daa.client_id = dc.client_id\n",
    "        left join usa_clients uc1 on dac.client_id  = uc1.client_id\n",
    "        left join fd_clients fd on fd.client_id = dac.client_id \n",
    "        left join target_savings_clients tsc on tsc.client_id = dac.client_id \n",
    "        left join child_savings_clients csc on csc.client_id = dac.client_id \n",
    "        left join corp_current_clients ccc on ccc.client_id = dac.client_id \n",
    "        left join ind_current_clients icc on icc.client_id = dac.client_id \n",
    "        left join staff_current_clients scc on scc.client_id = dac.client_id \n",
    "        left join credit_clients cc1 on cc1.client_id = dac.client_id \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''', conn)\n",
    "\n",
    "query_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7abaf3c-96e7-43f1-8cee-41595518cb44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "df = query_data\n",
    "display(df)\n",
    "\n",
    "# Create a SparkSession if not already created\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Write Spark DataFrame to table in Databricks\n",
    "spark_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"vfd_databricks.default.prod_chan_adoption\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5727b12c-ca27-473d-a60b-3db17878e80e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = query_data\n",
    "\n",
    "\n",
    "# Write DataFrame to Redshift\n",
    "# Assuming the table name should be 'wh_client_prod_chan_adoption'\n",
    "table_name = 'dwh_client_prod_chan_adoption'\n",
    "\n",
    "# Write the DataFrame to the Redshift table\n",
    "df.to_sql(name=table_name, con=conn, if_exists='replace', index=False, chunksize = 5000, method = 'multi')\n",
    "\n",
    "\n",
    "print(f\"Data successfully written on: {now}\\n \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "223d3ccc-7709-44ad-a500-d8ef85afff05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## resulting tables on redshift public schema includes \n",
    "\n",
    "* dwh_client_prod_chan_adoption  - list of product and channels in use by client (this excludes POS)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "client_prod_chan_adoption",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "dslab",
   "language": "python",
   "name": "dslab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
