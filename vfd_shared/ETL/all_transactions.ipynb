{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e9cde10-2009-4043-b446-c23d03306b73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Healthy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d62503a7-e0f6-4170-a863-b11dabb2a4a0",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from re import search\n",
    "from sqlalchemy import create_engine\n",
    "import duckdb\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import mysql.connector\n",
    "import json\n",
    "with open('/Workspace/Credentials/db_data.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "Dumpdb = mysql.connector.connect(\n",
    "  host=data['Dumpdb']['host'],\n",
    "  user=data['Dumpdb']['user'],\n",
    "  passwd=data['Dumpdb']['passwd'],\n",
    "  database = data['Dumpdb']['database']\n",
    ")\n",
    "\n",
    "\n",
    "Mifosdb = mysql.connector.connect(\n",
    "  host=data['mifos']['host'],\n",
    "  user=data['mifos']['user'],\n",
    "  passwd=data['mifos']['passwd'],\n",
    "  database = data['mifos']['database']\n",
    ")\n",
    "\n",
    "\n",
    "vbizdb = mysql.connector.connect(\n",
    "     host=data['vbizdb']['host'],\n",
    "  user=data['vbizdb']['user'],\n",
    "  passwd=data['vbizdb']['passwd'],\n",
    "  database = data['vbizdb']['database']\n",
    ")\n",
    "\n",
    "\n",
    "host = data['redshift']['host']\n",
    "user = data['redshift']['user']\n",
    "passwd = data['redshift']['passwd']\n",
    "database = data['redshift']['database']\n",
    "\n",
    "conn = create_engine(f\"postgresql+psycopg2://{user}:{passwd}@{host}:5439/{database}\")\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "yesterday =  (datetime.today() - timedelta(days = 1)).strftime('%Y-%m-%d')\n",
    "print(today)\n",
    "print(yesterday)\n",
    "\n",
    "\n",
    "last_2_wks = datetime.today() - timedelta(days = 14)\n",
    "last_2_wks = last_2_wks.strftime('%Y-%m-%d')\n",
    "print('------------------------------------')\n",
    "print(last_2_wks)\n",
    "\n",
    "print('\\n')\n",
    "now = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "last_30_mins = (datetime.today() - timedelta(days = 1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "trunc_last_30_mins = (datetime.today() - timedelta(days = 1)).strftime('%Y-%m-%d %H:%M')\n",
    "print(last_30_mins, 'to', now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7556dc5-6ed7-4baf-964c-664bb84b1d04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(datetime.today().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7162730c-d08b-459b-ab0e-ca13b60d01ec",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lastr = pd.read_sql_query(f'''\n",
    "                select \n",
    "                -- *\n",
    "                max(transaction_id) as ltr,\n",
    "                max(transaction_date) as last_date\n",
    "                from dwh_all_transactions\n",
    "                -- order by transaction_date\n",
    "                -- limit 100\n",
    "                ''', conn)\n",
    "\n",
    "ltr = (lastr['ltr'][0], lastr['last_date'][0])\n",
    "print(ltr[0], '-', ltr[1])\n",
    "\n",
    "lastr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9342871-434f-4f27-b610-cf30a3bcbe7c",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE - to crosscheck reversal status btw Jan-2020 to Nov-2020 using (is_reversed_by_contra_entry) column on msat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3789d34b-6ea5-4efa-908d-550731c9c85a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## All transactions ETL from MIFOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9754112d-a22e-4095-93e1-e8e56e848d43",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mifosdb = mysql.connector.connect(\n",
    "  host=data['mifos']['host'],\n",
    "  user=data['mifos']['user'],\n",
    "  passwd=data['mifos']['passwd'],\n",
    "  database = data['mifos']['database']\n",
    ")\n",
    "\n",
    "miftr = pd.read_sql_query(f'''\n",
    "                select\n",
    "                st.id as transaction_id,\n",
    "                \n",
    "                ifnull(mc.id, mg.id) as client_id,\n",
    "                ifnull(replace(mc.display_name, 'null', ''), mg.display_name) as client_name,\n",
    "                st.savings_account_id as account_id,\n",
    "                msa.account_no,\n",
    "                msp.name as product_name,\n",
    "                st.amount, \n",
    "                st.overdraft_amount_derived as overdraft_amount, \n",
    "                st.running_balance_derived as running_balance, \n",
    "                st.cumulative_balance_derived as cumulative_balance, \n",
    "                st.created_date transaction_date,   \n",
    "                case st.is_reversed_by_contra_entry\n",
    "                        when '0' then 'No'\n",
    "                        when '1' then 'Yes' end as is_reversed,\n",
    "                case st.is_loan_disbursement\n",
    "                        when 0 then 'No'\n",
    "                        when 1 then 'Yes' end as is_transaction_loan_disbursement,\n",
    "\n",
    "                map.username as transaction_initializer_username, \n",
    "                CONCAT(map.firstname, ' ', map.lastname) as transaction_initializer,\n",
    "                \n",
    "                st.transaction_type_enum, \n",
    "                renum.enum_value as transaction_type,\n",
    "                mpd.account_number as third_party_account_no, \n",
    "                mpd.check_number as channel, \n",
    "                mpd.receipt_number session_id, \n",
    "                mpd.bank_number, \n",
    "                mpd.routing_code,\n",
    "                \n",
    "                mpt.value as partners_description,\n",
    "                mtr.latitude, \n",
    "                mtr.longitude, \n",
    "                mtr.notes transaction_notes, \n",
    "                mtr.remarks transaction_remarks,\n",
    "                mtr.transaction_brand_name as third_party_name                \n",
    "                \n",
    "                from m_savings_account_transaction st\n",
    "                left join m_savings_account msa on msa.id = st.savings_account_id\n",
    "                left join m_savings_product msp on msp.id = msa.product_id\n",
    "                left join m_client mc on mc.id = msa.client_id\n",
    "                left join m_group mg on mg.id = msa.group_id\n",
    "                left join (SELECT\n",
    "                            rv.enum_name,\n",
    "                            rv.enum_id,\n",
    "                            rv.enum_message_property,\n",
    "                            rv.enum_value\n",
    "                            FROM r_enum_value rv\n",
    "                            WHERE rv.enum_name = 'savings_transaction_type_enum') renum on renum.enum_id = st.transaction_type_enum\n",
    "                left join m_appuser map on map.id = st.appuser_id\n",
    "                left JOIN m_payment_detail mpd ON mpd.id = st.payment_detail_id\n",
    "                left JOIN m_payment_type mpt ON mpt.id = mpd.payment_type_id\n",
    "                left join m_transaction_request mtr on mtr.transaction_id = st.id\n",
    "                where left(transaction_date, 4) >= '2019'\n",
    "                and  st.id > {ltr[0]}\n",
    "                LIMIT 50000\n",
    "                ''', Mifosdb)\n",
    "\n",
    "miftr['transaction_id'] = miftr['transaction_id'].astype(str)\n",
    "\n",
    "\n",
    "dump = pd.read_sql_query(f'''\n",
    "            select\n",
    "            resource_id as transaction_id,\n",
    "            response_code,\n",
    "            partners\n",
    "            from MM_BANK_SETTLEMENTS\n",
    "            where resource_id in ({','.join([str(x) for x in miftr['transaction_id'].tolist()])})\n",
    "            and partners != 'SAVI'\n",
    "            ''', Dumpdb)\n",
    "\n",
    "    \n",
    "full = pd.merge(miftr, dump, on ='transaction_id', how = 'left')\n",
    "\n",
    "full['transaction_id'] = full['transaction_id'].astype('int64')\n",
    "full['load_date'] = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc57fdab-c2eb-4968-8003-0de4557ea970",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91490600-48de-481b-97dd-8f1ed1a9e563",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "133d43a3-b05a-4559-b95f-785dd0117385",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#full.to_sql('dwh_all_transactions', conn, index = False, if_exists = 'append', chunksize = 10000, method = 'multi')\n",
    "\n",
    "#print(f'ETL Successful! as at {datetime.today()}')\n",
    "#print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b81fad43-66c1-4aae-9478-b1501d638fa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunk_size = 10000\n",
    "num_rows = len(full)\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "host = data['redshift']['host']\n",
    "user = data['redshift']['user']\n",
    "passwd = data['redshift']['passwd']\n",
    "database = data['redshift']['database']\n",
    "\n",
    "conn = create_engine(f\"postgresql+psycopg2://{user}:{passwd}@{host}:5439/{database}\")\n",
    "\n",
    "# Calculate the number of iterations needed\n",
    "num_iterations = (num_rows // chunk_size) + 1 if num_rows % chunk_size != 0 else num_rows // chunk_size\n",
    "\n",
    "# Loop through the DataFrame in chunks and insert into the database\n",
    "for i in range(num_iterations):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = (i + 1) * chunk_size if (i + 1) * chunk_size < num_rows else num_rows\n",
    "    \n",
    "    # Extract the chunk of data\n",
    "    chunk_df = full.iloc[start_idx:end_idx]\n",
    "    \n",
    "    # Use df.to_sql() to insert the chunk into the database\n",
    "    chunk_df.to_sql(\"dwh_all_transactions\", conn, index = False, if_exists = 'append', chunksize = 5000, method = 'multi')\n",
    "\n",
    "\n",
    "print(f'ETL Successful! as at {datetime.today()}')\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41325d68-10c5-4ed5-a597-5a6672b3e05e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Paycode / Cardless transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a1ef10c-2e54-4a91-b9ed-10f2d04bdf1c",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "paycode = pd.read_sql(f'''\n",
    "                select \n",
    "                id,\n",
    "                resource_id as transaction_id,\n",
    "                reference,\n",
    "                account_number,\n",
    "                account_id,\n",
    "                amount,\n",
    "                transaction_ref,\n",
    "                -- response_message,\n",
    "                response_code,\n",
    "                channel,\n",
    "                partners,\n",
    "                posting_date as transaction_date,\n",
    "                resource_rvs_id,\n",
    "                posting_rvs_date,\n",
    "                modified as modified_date,\n",
    "                paycode_withdrawal_resource_id,\n",
    "                paycode_trans_id,\n",
    "                is_set_for_paycode_reversal\n",
    "                paycode_withdrawal_reversal_resource_id,\n",
    "                now() as load_date\n",
    "                from MM_BANK_SETTLEMENTS\n",
    "                where partners = 'PAYCODE'\n",
    "                ''', Dumpdb)\n",
    "\n",
    "paycode['resource_rvs_id'] = paycode['resource_rvs_id'].fillna(0).astype('int64')\n",
    "paycode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0628d581-2e9a-4dea-8e56-5b7a1cf1211b",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#paycode.to_sql(\"dwh_paycode_transactions\", conn, index = False, if_exists = 'replace', chunksize = 10000, method = 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be97baf4-fefa-439a-8446-26ed6f548acc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunk_size = 10000\n",
    "num_rows = len(paycode)\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "conn = create_engine(f\"postgresql+psycopg2://{user}:{passwd}@{host}:5439/{database}\")\n",
    "\n",
    "# Calculate the number of iterations needed\n",
    "num_iterations = (num_rows // chunk_size) + 1 if num_rows % chunk_size != 0 else num_rows // chunk_size\n",
    "\n",
    "# Loop through the DataFrame in chunks and insert into the database\n",
    "for i in range(num_iterations):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = (i + 1) * chunk_size if (i + 1) * chunk_size < num_rows else num_rows\n",
    "    \n",
    "    # Extract the chunk of data\n",
    "    chunk_df = paycode.iloc[start_idx:end_idx]\n",
    "    \n",
    "    # Use df.to_sql() to insert the chunk into the database\n",
    "    chunk_df.to_sql(\"dwh_paycode_transactions\", conn, index = False, if_exists = 'append', chunksize = 5000, method = 'multi')\n",
    "\n",
    "\n",
    "print(f'ETL Successful! as at {datetime.today()}')\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d49fc0-05ce-42f0-9d24-6b52dcdf3e53",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "Mifosdb = mysql.connector.connect(\n",
    "  host=data['mifos']['host'],\n",
    "  user=data['mifos']['user'],\n",
    "  passwd=data['mifos']['passwd'],\n",
    "  database = data['mifos']['database']\n",
    ")\n",
    "\n",
    "df = pd.read_sql_query(f\"\"\"\n",
    "    select\n",
    "    dac.client_id,\n",
    "    dac.client_name,\n",
    "    dac.client_status,\n",
    "    dac.country,\n",
    "    dac.client_gender,\n",
    "    dac.client_type,\n",
    "    dac.client_tier,\n",
    "    dac.client_category ,\n",
    "    daa.account_no,\n",
    "    dab.approvedon_date,\n",
    "    dab.closedon_date ,\n",
    "    dab.balance,\n",
    "    dab.product_id,\n",
    "    daa.product_name,\n",
    "    dpt.short_name,\n",
    "    dpt.description\n",
    "from\n",
    "    dwh_all_clients dac\n",
    "left join\n",
    "  dwh_all_accounts daa\n",
    "on\n",
    "    dac.client_id = daa.client_id\n",
    "left join\n",
    "  dwh_account_balances dab\n",
    "on\n",
    "    daa.account_no = dab.account_no\n",
    "left join\n",
    "  dwh_product_types dpt\n",
    "on\n",
    "    daa.product_id = dpt.product_id\n",
    "where\n",
    "    UPPER(dac.lastname) = 'OMOTAYO';\n",
    "    \"\"\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805cd4fb-b6b3-4f4c-a9bf-1aece3d7f367",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Check for duplicates on all transactions table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36caef56-9a75-414c-a6c1-77289f5b9ced",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "ch = \"\"\"\n",
    "select \n",
    "transaction_id,\n",
    "count(*)\n",
    "from dwh_all_transactions\n",
    "group by 1\n",
    "having count(transaction_id ) > 1\n",
    "LIMIT 300000\n",
    "\"\"\"\n",
    "\n",
    "df_ch = pd.read_sql_query(ch, conn)\n",
    "print(len(df_ch))\n",
    "\n",
    "\n",
    "\n",
    "if len(df_ch) > 0:\n",
    "\n",
    "    dups = ','.join([str(x) for x in df_ch['transaction_id'].tolist()])\n",
    "\n",
    "    ac = f\"\"\"\n",
    "    select \n",
    "    distinct *\n",
    "    from dwh_all_transactions\n",
    "    where transaction_id in ({dups})\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(ac, conn)\n",
    "\n",
    "    # delete rows from table on redshift SQL server\n",
    "    sql = f'''\n",
    "        DELETE FROM dwh_all_transactions\n",
    "        WHERE \"transaction_id\" in ({dups})\n",
    "       '''\n",
    "\n",
    "    with conn.begin() as engine:\n",
    "        engine.execute(sql)\n",
    "\n",
    "    df.to_sql('dwh_all_transactions', conn, index=False, if_exists='append', chunksize=10000, method='multi')\n",
    "    \n",
    "else:\n",
    "    print('no airtime duplicates found!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e97493c9-53a2-478b-ae47-4e47b14a3005",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "all_transactions",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
