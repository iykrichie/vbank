{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d916c93d-73da-4036-aafb-77bfbe38d9d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Healthy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13ac496-6db4-4682-8994-ffd4af7eb6ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from re import search\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e55d9ed-dd27-4e5a-b35d-3867cedaa25c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "yesterday =  (datetime.today() - timedelta(days = 1)).strftime('%Y-%m-%d')\n",
    "yesterday = 'Jun-05 to Jun-20'\n",
    "yesterday_format2 =  (datetime.today() - timedelta(days = 1)).strftime('%b_%d')\n",
    "print(yesterday)\n",
    "print(yesterday_format2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0efde261-2c26-4ef9-b46e-4099ebbec8aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from re import search\n",
    "from sqlalchemy import create_engine\n",
    "import duckdb\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import json\n",
    "with open('/Workspace/Credentials/db_data.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "\n",
    "Mifosdb = mysql.connector.connect(\n",
    "  host=data['mifos']['host'],\n",
    "  user=data['mifos']['user'],\n",
    "  passwd=data['mifos']['passwd'],\n",
    "  database = data['mifos']['database']\n",
    ")\n",
    "\n",
    "\n",
    "host = data['redshift']['host']\n",
    "user = data['redshift']['user']\n",
    "passwd = data['redshift']['passwd']\n",
    "database = data['redshift']['database']\n",
    "\n",
    "conn = create_engine(f\"postgresql+psycopg2://{user}:{passwd}@{host}:5439/{database}\")\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124151fd-1468-4316-bd3c-449c78a374ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "username = data['auto-report']['email']\n",
    "passwd = data['auto-report']['passwd']\n",
    "print(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d281cdc8-ba1d-49a2-8bb7-6338c5eb5376",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "staff = pd.read_excel(\"/Workspace/ReportDump/Staff_List/Feb 24 Staff List.xlsx\")\n",
    "staff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "849201c7-2cfb-4c22-b9b0-935a94fc9965",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql = f'''\n",
    "SELECT\n",
    "sa.account_no,\n",
    "mc.display_name AS staff_name,\n",
    "mc.id AS staff_client_id,\n",
    "mc.referral_id\n",
    "FROM m_savings_account sa\n",
    "JOIN m_client mc ON mc.id = sa.client_id\n",
    "WHERE sa.account_no IN ({','.join(str(x) for x in staff['Account Numbers'])})\n",
    "AND mc.referral_id IS NOT NULL\n",
    "GROUP BY mc.id\n",
    "\n",
    "'''\n",
    "staff = pd.read_sql_query(sql, Mifosdb)\n",
    "\n",
    "other_staff = {\n",
    "    'account_no': [''],\n",
    "    'staff_name': [''],\n",
    "    'staff_client_id': ['others'],\n",
    "    'referral_id': [''],\n",
    "}\n",
    "\n",
    "other_staff = pd.DataFrame(other_staff)\n",
    "staff = staff.append(other_staff, ignore_index=True)\n",
    "\n",
    "staff.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0628a122-41e6-4d2b-83f5-0e41c3a81abd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(staff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f30cce74-c63d-4881-bcef-760d3c2187ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MIFOS_DB\n",
    "mifos_driver = \"org.mariadb.jdbc.Driver\"\n",
    "mifos_database_host = data['mifos']['host']\n",
    "mifos_database_port = \"3306\" # update if you use a non-default port\n",
    "mifos_database_name = data['mifos']['database']\n",
    "mifos_user=data['mifos']['user']\n",
    "mifos_password = data['mifos']['passwd']\n",
    "mifos_url = f\"jdbc:mysql://{mifos_database_host}:{mifos_database_port}/{mifos_database_name}\"\n",
    "\n",
    "# Define function to extract data from dbs\n",
    "def extract_function(query, url, user, password):\n",
    "    df = spark.read \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"query\", query) \\\n",
    "                .option(\"url\", url) \\\n",
    "                .option(\"user\", user) \\\n",
    "                .option(\"password\", password) \\\n",
    "                .option(\"connectTimeout\", \"1000\") \\\n",
    "                .option(\"treatEmptyValueAsNulls\",\"true\") \\\n",
    "                .option(\"maxRowsInMemory\",200) \\\n",
    "                .load()\n",
    "    return df\n",
    "\n",
    "\n",
    "## For Mifos\n",
    "sql = f'''\n",
    "SELECT\n",
    "mc.referred_by_id AS staff_client_id,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-05' THEN st.amount END),0) AS Jun_05_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-06' THEN st.amount END),0) AS Jun_06_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-07' THEN st.amount END),0) AS Jun_07_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-08' THEN st.amount END),0) AS Jun_08_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-09' THEN st.amount END),0) AS Jun_09_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-10' THEN st.amount END),0) AS Jun_10_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-11' THEN st.amount END),0) AS Jun_11_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-12' THEN st.amount END),0) AS Jun_12_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-13' THEN st.amount END),0) AS Jun_13_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-14' THEN st.amount END),0) AS Jun_14_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-15' THEN st.amount END),0) AS Jun_15_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-16' THEN st.amount END),0) AS Jun_16_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-17' THEN st.amount END),0) AS Jun_17_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-18' THEN st.amount END),0) AS Jun_18_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-19' THEN st.amount END),0) AS Jun_19_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-20' THEN st.amount END),0) AS Jun_20_total_inflow,\n",
    "\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-05' then st.amount END),0) AS Jun_05_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-06' then st.amount END),0) AS Jun_06_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-07' then st.amount END),0) AS Jun_07_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-08' then st.amount END),0) AS Jun_08_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-09' then st.amount END),0) AS Jun_09_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-10' then st.amount END),0) AS Jun_10_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-11' then st.amount END),0) AS Jun_11_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-12' then st.amount END),0) AS Jun_12_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-13' then st.amount END),0) AS Jun_13_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-14' then st.amount END),0) AS Jun_14_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-15' then st.amount END),0) AS Jun_15_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-16' then st.amount END),0) AS Jun_16_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-17' then st.amount END),0) AS Jun_17_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-18' then st.amount END),0) AS Jun_18_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-19' then st.amount END),0) AS Jun_19_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-20' then st.amount END),0) AS Jun_20_FD_inflow\n",
    "FROM m_savings_account sa\n",
    "JOIN m_client mc ON mc.id = sa.client_id\n",
    "JOIN m_savings_product sp ON sp.id = sa.product_id\n",
    "LEFT JOIN m_savings_account_transaction st ON st.savings_account_id = sa.id\n",
    "WHERE st.transaction_type_enum = 1\n",
    "AND left(st.transaction_date,10) >= '2024-06-05'\n",
    "AND left(st.transaction_date,10) <= '2024-06-20'\n",
    "AND mc.referred_by_id IN ({','.join(str(x) for x in staff['staff_client_id'])})\n",
    "GROUP BY mc.referred_by_id\n",
    "'''       \n",
    "# apply function\n",
    "mifos_df = extract_function(query=sql, url=mifos_url, user=mifos_user, password=mifos_password)\n",
    "mifos_df.persist()\n",
    "deposit = mifos_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8f26c88-8744-44c2-8c85-fd787ebb813b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MIFOS_DB\n",
    "mifos_driver = \"org.mariadb.jdbc.Driver\"\n",
    "mifos_database_host = data['mifos']['host']\n",
    "mifos_database_port = \"3306\" # update if you use a non-default port\n",
    "mifos_database_name = data['mifos']['database']\n",
    "mifos_user=data['mifos']['user']\n",
    "mifos_password = data['mifos']['passwd']\n",
    "mifos_url = f\"jdbc:mysql://{mifos_database_host}:{mifos_database_port}/{mifos_database_name}\"\n",
    "\n",
    "# Define function to extract data from dbs\n",
    "def extract_function(query, url, user, password):\n",
    "    df = spark.read \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"query\", query) \\\n",
    "                .option(\"url\", url) \\\n",
    "                .option(\"user\", user) \\\n",
    "                .option(\"password\", password) \\\n",
    "                .option(\"connectTimeout\", \"1000\") \\\n",
    "                .option(\"treatEmptyValueAsNulls\",\"true\") \\\n",
    "                .option(\"maxRowsInMemory\",200) \\\n",
    "                .load()\n",
    "    return df\n",
    "\n",
    "\n",
    "## For Mifos\n",
    "sql = f'''\n",
    "SELECT\n",
    "CASE WHEN mc.referred_by_id IS NULL THEN 'others' ELSE mc.referred_by_id END AS staff_client_id,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-05' THEN st.amount END),0) AS Jun_05_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-06' THEN st.amount END),0) AS Jun_06_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-07' THEN st.amount END),0) AS Jun_07_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-08' THEN st.amount END),0) AS Jun_08_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-09' THEN st.amount END),0) AS Jun_09_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-10' THEN st.amount END),0) AS Jun_10_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-11' THEN st.amount END),0) AS Jun_11_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-12' THEN st.amount END),0) AS Jun_12_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-13' THEN st.amount END),0) AS Jun_13_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-14' THEN st.amount END),0) AS Jun_14_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-15' THEN st.amount END),0) AS Jun_15_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-16' THEN st.amount END),0) AS Jun_16_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-17' THEN st.amount END),0) AS Jun_17_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-18' THEN st.amount END),0) AS Jun_18_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-19' THEN st.amount END),0) AS Jun_19_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-20' THEN st.amount END),0) AS Jun_20_total_inflow,\n",
    "\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-21' THEN st.amount END),0) AS Jun_21_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-22' THEN st.amount END),0) AS Jun_22_total_inflow,\n",
    "IFNULL(SUM(CASE WHEN left(st.transaction_date,10) = '2024-06-23' THEN st.amount END),0) AS Jun_23_total_inflow,\n",
    "\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-05' then st.amount END),0) AS Jun_05_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-06' then st.amount END),0) AS Jun_06_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-07' then st.amount END),0) AS Jun_07_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-08' then st.amount END),0) AS Jun_08_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-09' then st.amount END),0) AS Jun_09_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-10' then st.amount END),0) AS Jun_10_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-11' then st.amount END),0) AS Jun_11_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-12' then st.amount END),0) AS Jun_12_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-13' then st.amount END),0) AS Jun_13_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-14' then st.amount END),0) AS Jun_14_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-15' then st.amount END),0) AS Jun_15_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-16' then st.amount END),0) AS Jun_16_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-17' then st.amount END),0) AS Jun_17_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-18' then st.amount END),0) AS Jun_18_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-19' then st.amount END),0) AS Jun_19_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-20' then st.amount END),0) AS Jun_20_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-21' then st.amount END),0) AS Jun_21_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-22' then st.amount END),0) AS Jun_22_FD_inflow,\n",
    "IFNULL(SUM(CASE WHEN sa.product_id = '36' and left(st.transaction_date,10) = '2024-06-23' then st.amount END),0) AS Jun_23_FD_inflow\n",
    "FROM m_savings_account sa\n",
    "JOIN m_client mc ON mc.id = sa.client_id\n",
    "JOIN m_savings_product sp ON sp.id = sa.product_id\n",
    "LEFT JOIN m_savings_account_transaction st ON st.savings_account_id = sa.id\n",
    "WHERE st.transaction_type_enum = 1\n",
    "AND left(st.transaction_date,10) >= '2024-06-05'\n",
    "AND left(st.transaction_date,10) <= '2024-06-23'\n",
    "AND mc.referred_by_id IS NULL\n",
    "GROUP BY mc.referred_by_id\n",
    "'''       \n",
    "# apply function\n",
    "mifos_df = extract_function(query=sql, url=mifos_url, user=mifos_user, password=mifos_password)\n",
    "mifos_df.persist()\n",
    "deposit = mifos_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c99c72f4-aef9-447c-8a82-af3bd9d52275",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deposit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71ea5ccc-2fbe-4068-8299-aa781caae1f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_df = staff[['staff_client_id', 'staff_name','referral_id']].merge(deposit, on = 'staff_client_id', how = 'left')\n",
    "#full_df = full_df.sort_values(by=['staff_client_id'], ascending=False)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37dd564e-db05-4228-9c11-902c93e0b592",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4848cdd-6af8-4298-bda1-430b4988007b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"/Workspace/ReportDump/Deposit_Drive/Deposit_Drive_{yesterday}.xlsx\") as writer:\n",
    "    full_df.to_excel(writer, sheet_name = f'{yesterday}', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af5f9bfa-e4f2-4905-a7ae-ce6510895f3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# FILE TO SEND AND ITS PATH\n",
    "filename = f'Deposit_Drive_{yesterday}.xlsx'\n",
    "SourcePathName  = \"/Workspace/ReportDump/Deposit_Drive/\" + filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdeb373a-512f-490c-88b8-3bcd82d01bf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import csv, smtplib, ssl\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.text import MIMEText\n",
    "from email import encoders\n",
    "\n",
    "#rotimi.awofisibe@vfd-mfb.com, mercy.ejemudaro@vfd-mfb.com, \n",
    "\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = 'auto-report@vfdtech.ng'\n",
    "msg['To'] = 'Oladapo.Omolaja@vfdtech.ng'\n",
    "#msg['CC'] = 'data-team@vfdtech.ng'\n",
    "msg['Subject'] = f'Staff Deposit Drive {yesterday}'\n",
    "body = f\"\"\"\n",
    "Hello Team,\n",
    "\n",
    "Please find attached report for {yesterday}.\n",
    "\n",
    "Regards,\n",
    "DBR\n",
    "\"\"\"\n",
    "msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "\n",
    "\n",
    "## ATTACHMENT PART OF THE CODE IS HERE\n",
    "attachment = open(SourcePathName, 'rb')\n",
    "part = MIMEBase('application', \"octet-stream\")\n",
    "part.set_payload((attachment).read())\n",
    "encoders.encode_base64(part)\n",
    "part.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
    "msg.attach(part)\n",
    "\n",
    "server = smtplib.SMTP('smtp.office365.com', 587)  ### put your relevant SMTP here\n",
    "server.ehlo()\n",
    "server.starttls()\n",
    "server.ehlo()\n",
    "server.login(username, passwd)  ### if applicable\n",
    "server.send_message(msg)\n",
    "server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78077bd8-6112-4274-9ced-57f670f00baa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Dev_Staff Deposit Drive",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
